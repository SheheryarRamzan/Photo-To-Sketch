# Photo-To-Sketch

For this project, we are going to investigate and compare the conver gence abilities of VAEs, autoencoders, Pix2Pix GANs and the UNET model in translating images into hand-drawn sketches. Different model structures and training strategies were used to attain high-level sketch drawing. In the research article, two performance evaluating metrics, i.e. 'Peak Signal-to-Noise Ratio' (PSNR) and 'Structural Similarity Index Measure' (SSIM) are used to compare ground truth sketches. Both of them are indices often used to measure the fidelity of reconstructed or generated images relative to a given image. "CUHK" and "CelebA" datasets were employed for training and test these two data sets contain many images together with corresponding hand-drawn sketch. This study reveals the capacity and limitation of these models as relevant in the science of image-to-image translation; these models have potential use in art and design. 
